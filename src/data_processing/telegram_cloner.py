#!/usr/bin/env python3
"""
–ö–ª–æ–Ω–µ—Ä –¥–∏–∞–ª–æ–≥–æ–≤ —á–µ—Ä–µ–∑ Telegram API –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–∞—à–µ–≥–æ —Å—Ç–∏–ª—è –æ–±—â–µ–Ω–∏—è
"""

import asyncio
from telethon import TelegramClient
from telethon.tl.types import Message, User, Chat, Channel
from pathlib import Path
import json
from datetime import datetime
from typing import Dict, List, Optional
import re


class TelegramStyleCloner:
    """–ö–ª–æ–Ω–∏—Ä—É–µ—Ç –≤–∞—à —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –∏–∑ Telegram"""

    def __init__(self, config):
        self.config = config
        self.api_id = config.telegram.api_id
        self.api_hash = config.telegram.api_hash
        self.phone = config.telegram.phone
        self.session_name = config.telegram.session_name

        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
        self.cloned_dir = Path(config.paths.cloned_data)
        self.style_profiles_dir = Path(config.paths.style_profiles)
        self.cloned_dir.mkdir(parents=True, exist_ok=True)
        self.style_profiles_dir.mkdir(parents=True, exist_ok=True)

        self.client = None

    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ Telegram"""
        print("üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Telegram...")
        self.client = TelegramClient(
            self.session_name,
            self.api_id,
            self.api_hash,
            device_model="Personal Communication Assistant",
            system_version="1.0",
            app_version="1.0.0"
        )

        await self.client.start(phone=self.phone)
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ")
        return self.client

    async def analyze_dialog_context(self, dialog) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞"""
        dialog_name = dialog.name or dialog.title or "Unknown"

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–∏–∞–ª–æ–≥–∞
        if dialog.is_user:
            # –õ–∏—á–Ω—ã–π –¥–∏–∞–ª–æ–≥
            user = await self.client.get_entity(dialog.entity)
            if hasattr(user, 'username'):
                return f"personal_{user.username or 'user'}"
            return "personal"

        elif dialog.is_group:
            # –ì—Ä—É–ø–ø–æ–≤–æ–π —á–∞—Ç
            if "—Å–µ–º—å—è" in dialog_name.lower() or "family" in dialog_name.lower():
                return "family"
            elif "—Ä–∞–±–æ—Ç–∞" in dialog_name.lower() or "work" in dialog_name.lower():
                return "professional"
            elif any(word in dialog_name.lower() for word in ["–¥—Ä—É–∑—å—è", "friends", "—Ç—É—Å–æ–≤–∫–∞"]):
                return "friendly"
            else:
                return "group"

        elif dialog.is_channel:
            return "channel"

        return "unknown"

    async def extract_my_messages(self, dialog, context: str, limit: int = 1000) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –¥–∏–∞–ª–æ–≥–∞"""
        my_messages = []

        try:
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–π ID
            me = await self.client.get_me()
            my_id = me.id

            async for message in self.client.iter_messages(dialog, limit=limit):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                if not message.sender or message.sender.id != my_id:
                    continue

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                if not message.text or len(message.text.strip()) < 2:
                    continue

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                if message.text.startswith('```') or message.text.startswith('/'):
                    continue

                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
                context_messages = await self._get_message_context(message, dialog)

                msg_data = {
                    'text': message.text,
                    'date': message.date.isoformat() if message.date else None,
                    'message_id': message.id,
                    'dialog_id': dialog.id,
                    'dialog_name': dialog.name or dialog.title,
                    'context_type': context,
                    'context_messages': context_messages,
                    'has_media': bool(message.media),
                    'message_type': self._classify_message_type(message.text)
                }

                my_messages.append(msg_data)

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")

        return my_messages

    async def _get_message_context(self, message, dialog, num_context: int = 3) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è"""
        context_messages = []

        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–µ—Ä–µ–¥ —Ç–µ–∫—É—â–∏–º
            async for prev_msg in self.client.iter_messages(
                    dialog,
                    limit=num_context,
                    offset_id=message.id,
                    reverse=True
            ):
                if prev_msg.id == message.id:
                    continue

                if prev_msg.text and len(prev_msg.text.strip()) > 1:
                    sender_prefix = "–Ø: " if prev_msg.sender and prev_msg.sender.id == message.sender.id else "–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: "
                    context_messages.append(f"{sender_prefix}{prev_msg.text}")

        except:
            pass

        return context_messages

    def _classify_message_type(self, text: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è"""
        text_lower = text.lower()

        # –í–æ–ø—Ä–æ—Å—ã
        if text.endswith('?') or any(word in text_lower for word in ['–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É']):
            return 'question'

        # –í–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è
        if text.endswith('!') or any(word in text_lower for word in ['–∫–ª–∞—Å—Å', '–æ—Ç–ª–∏—á–Ω–æ', '—Å—É–ø–µ—Ä', '—É—Ä–∞']):
            return 'exclamation'

        # –ö–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        if len(text.split()) <= 3:
            return 'short'

        # –î–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        if len(text.split()) > 20:
            return 'long'

        # –°–æ–æ–±—â–µ–Ω–∏—è —Å —ç–º–æ–¥–∑–∏
        if any(emoji in text for emoji in ['üòÄ', 'üòÇ', 'üòä', 'üòç', 'üòé', 'ü§î', 'üëç']):
            return 'with_emoji'

        return 'normal'

    async def clone_my_style(self):
        """–ö–ª–æ–Ω–∏—Ä—É–µ—Ç –º–æ–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –∏–∑ –≤—Å–µ—Ö –¥–∏–∞–ª–æ–≥–æ–≤"""
        print("\nüé≠ –ö–õ–û–ù–ò–†–û–í–ê–ù–ò–ï –í–ê–®–ï–ì–û –°–¢–ò–õ–Ø –û–ë–©–ï–ù–ò–Ø")
        print("=" * 50)

        client = await self.connect()

        try:
            print("üìÅ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤...")
            dialogs = await client.get_dialogs(limit=50)

            all_my_messages = []
            context_stats = {}

            for dialog in dialogs:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
                context = await self.analyze_dialog_context(dialog)
                dialog_name = dialog.name or dialog.title or f"Dialog_{dialog.id}"

                print(f"\nüì® –î–∏–∞–ª–æ–≥: {dialog_name} ({context})")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
                messages = await self.extract_my_messages(
                    dialog,
                    context,
                    limit=self.config.telegram.max_messages_per_dialog
                )

                if messages:
                    all_my_messages.extend(messages)

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    if context not in context_stats:
                        context_stats[context] = 0
                    context_stats[context] += len(messages)

                    print(f"   üìù –ú–æ–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {len(messages)}")

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è —ç—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞
                    dialog_file = self.cloned_dir / f"dialog_{dialog.id}_{context}.json"
                    with open(dialog_file, 'w', encoding='utf-8') as f:
                        json.dump({
                            'dialog_id': dialog.id,
                            'dialog_name': dialog_name,
                            'context': context,
                            'messages': messages,
                            'export_date': datetime.now().isoformat()
                        }, f, ensure_ascii=False, indent=2)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            if all_my_messages:
                # –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
                main_file = self.cloned_dir / "my_communication_style.json"
                with open(main_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'total_messages': len(all_my_messages),
                        'context_stats': context_stats,
                        'export_date': datetime.now().isoformat(),
                        'messages': all_my_messages
                    }, f, ensure_ascii=False, indent=2)

                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å —Å—Ç–∏–ª—è
                style_profile = self.create_style_profile(all_my_messages)

                print(f"\n‚úÖ –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                print(f"üìä –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(all_my_messages)}")
                print(f"üìÅ –ö–æ–Ω—Ç–µ–∫—Å—Ç—ã: {context_stats}")
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {main_file}")
                print(f"üé≠ –ü—Ä–æ—Ñ–∏–ª—å —Å—Ç–∏–ª—è —Å–æ–∑–¥–∞–Ω: {style_profile}")

                return main_file, style_profile
            else:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞—à–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
                return None, None

        finally:
            await client.disconnect()

    def create_style_profile(self, messages: List[Dict]) -> Path:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å —Å—Ç–∏–ª—è –æ–±—â–µ–Ω–∏—è"""
        print("\nüé® –ê–Ω–∞–ª–∏–∑ –≤–∞—à–µ–≥–æ —Å—Ç–∏–ª—è –æ–±—â–µ–Ω–∏—è...")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å
        style_analysis = {
            'average_message_length': 0,
            'emoji_frequency': 0,
            'question_frequency': 0,
            'exclamation_frequency': 0,
            'word_usage': {},
            'context_preferences': {},
            'message_type_distribution': {}
        }

        total_messages = len(messages)

        for msg in messages:
            text = msg['text']

            # –î–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
            words = text.split()
            style_analysis['average_message_length'] += len(words)

            # –≠–º–æ–¥–∑–∏
            if any(emoji in text for emoji in ['üòÄ', 'üòÇ', 'üòä', 'üòç', 'üòé']):
                style_analysis['emoji_frequency'] += 1

            # –í–æ–ø—Ä–æ—Å—ã
            if '?' in text:
                style_analysis['question_frequency'] += 1

            # –í–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è
            if '!' in text:
                style_analysis['exclamation_frequency'] += 1

            # –¢–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è
            msg_type = msg.get('message_type', 'normal')
            if msg_type not in style_analysis['message_type_distribution']:
                style_analysis['message_type_distribution'][msg_type] = 0
            style_analysis['message_type_distribution'][msg_type] += 1

            # –ö–æ–Ω—Ç–µ–∫—Å—Ç
            context = msg.get('context_type', 'unknown')
            if context not in style_analysis['context_preferences']:
                style_analysis['context_preferences'][context] = 0
            style_analysis['context_preferences'][context] += 1

            # –ß–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞ (–±–µ–∑ —Å—Ç–æ–ø-—Å–ª–æ–≤)
            common_words = self._extract_common_words(text)
            for word in common_words:
                if word not in style_analysis['word_usage']:
                    style_analysis['word_usage'][word] = 0
                style_analysis['word_usage'][word] += 1

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        if total_messages > 0:
            style_analysis['average_message_length'] /= total_messages
            style_analysis['emoji_frequency'] /= total_messages
            style_analysis['question_frequency'] /= total_messages
            style_analysis['exclamation_frequency'] /= total_messages

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å
        profile_file = self.style_profiles_dir / "my_style_profile.json"

        with open(profile_file, 'w', encoding='utf-8') as f:
            json.dump({
                'analysis_date': datetime.now().isoformat(),
                'total_messages_analyzed': total_messages,
                'style_analysis': style_analysis,
                'summary': self._create_style_summary(style_analysis)
            }, f, ensure_ascii=False, indent=2)

        return profile_file

    def _extract_common_words(self, text: str, min_length: int = 3) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞"""
        # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        words = re.findall(r'\b[–∞-—è—ë]{3,}\b', text.lower())

        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        stop_words = {'—ç—Ç–æ', '–∫–∞–∫', '—Ç–∞–∫', '–∏', '–≤', '–Ω–∞–¥', '–∫', '–¥–æ', '–Ω–µ', '–Ω–∞', '–Ω–æ', '–∑–∞', '—Ç–æ',
                      '—Å', '–ª–∏', '–∞', '–≤–æ', '–æ—Ç', '—Å–æ', '–¥–ª—è', '–æ', '–∂–µ', '–Ω—É', '–≤—ã', '–±—ã', '—á—Ç–æ',
                      '–∫—Ç–æ', '–æ–Ω', '–æ–Ω–∞'}

        return [word for word in words if word not in stop_words]

    def _create_style_summary(self, analysis: Dict) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ —Å—Ç–∏–ª—é"""
        summary = {
            'message_length': '–ö–æ—Ä–æ—Ç–∫–∏–µ' if analysis['average_message_length'] < 5 else
            '–°—Ä–µ–¥–Ω–∏–µ' if analysis['average_message_length'] < 15 else '–î–ª–∏–Ω–Ω—ã–µ',
            'emoji_usage': '–†–µ–¥–∫–æ' if analysis['emoji_frequency'] < 0.1 else
            '–£–º–µ—Ä–µ–Ω–Ω–æ' if analysis['emoji_frequency'] < 0.3 else '–ß–∞—Å—Ç–æ',
            'question_style': '–ú–∞–ª–æ –≤–æ–ø—Ä–æ—Å–æ–≤' if analysis['question_frequency'] < 0.1 else
            '–£–º–µ—Ä–µ–Ω–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤' if analysis['question_frequency'] < 0.3 else '–ú–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤',
            'emotionality': '–°–¥–µ—Ä–∂–∞–Ω–Ω—ã–π' if analysis['exclamation_frequency'] < 0.1 else
            '–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π' if analysis['exclamation_frequency'] < 0.3 else '–û—á–µ–Ω—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π'
        }

        # –°–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
        if analysis['context_preferences']:
            top_contexts = sorted(
                analysis['context_preferences'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:3]
            summary['top_contexts'] = [ctx for ctx, _ in top_contexts]

        # –°–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞
        if analysis['word_usage']:
            top_words = sorted(
                analysis['word_usage'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]
            summary['top_words'] = [word for word, _ in top_words]

        return summary


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∏–ª—è"""
    import yaml
    from pathlib import Path

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_path = Path("config.yaml")
    if not config_path.exists():
        print("‚ùå –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return

    with open(config_path, 'r', encoding='utf-8') as f:
        config_dict = yaml.safe_load(f)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("üöÄ –ó–∞–ø—É—Å–∫ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∞—à–µ–≥–æ —Å—Ç–∏–ª—è –æ–±—â–µ–Ω–∏—è...")

    cloner = TelegramStyleCloner(config_dict)

    try:
        asyncio.run(cloner.clone_my_style())
    except KeyboardInterrupt:
        print("\nüëã –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")


if __name__ == "__main__":
    main()