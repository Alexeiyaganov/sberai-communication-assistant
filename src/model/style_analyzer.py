#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç–∏–ª–µ–π –æ–±—â–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
"""

import re
from typing import Dict, List, Tuple
from dataclasses import dataclass
import numpy as np


@dataclass
class CommunicationStyle:
    """–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è"""
    context: str  # professional, family, romantic, friendly, creative
    formality: float  # 0.0-1.0
    emotionality: float  # 0.0-1.0
    humor_level: float  # 0.0-1.0
    emoji_frequency: float  # 0.0-1.0
    typical_length: str  # short, medium, long
    common_phrases: List[str]
    avoid_phrases: List[str]


class CommunicationStyleAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç–∏–ª–µ–π –æ–±—â–µ–Ω–∏—è"""

    def __init__(self, config):
        self.config = config
        self.contexts = config.communication_contexts

        # –®–∞–±–ª–æ–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
        self.context_patterns = self._load_context_patterns()

        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        self.stop_words = {
            '—ç—Ç–æ', '–∫–∞–∫', '—Ç–∞–∫', '–∏', '–≤', '–Ω–∞–¥', '–∫', '–¥–æ', '–Ω–µ', '–Ω–∞',
            '–Ω–æ', '–∑–∞', '—Ç–æ', '—Å', '–ª–∏', '–∞', '–≤–æ', '–æ—Ç', '—Å–æ', '–¥–ª—è', '–æ'
        }

    def _load_context_patterns(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤"""
        return {
            'professional': {
                'formality_words': ['—É–≤–∞–∂–∞–µ–º—ã–π', '–∫–æ–ª–ª–µ–≥–∞', '–ø—Ä–æ—à—É', '–ø—Ä–µ–¥–ª–∞–≥–∞—é', '—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ'],
                'emotional_words': [],
                'humor_words': [],
                'typical_length': 'medium',
                'common_endings': ['–° —É–≤–∞–∂–µ–Ω–∏–µ–º', '–ë–ª–∞–≥–æ–¥–∞—Ä—é', '–° –Ω–∞–∏–ª—É—á—à–∏–º–∏ –ø–æ–∂–µ–ª–∞–Ω–∏—è–º–∏']
            },
            'family': {
                'formality_words': [],
                'emotional_words': ['–ª—é–±–ª—é', '–æ–±–Ω–∏–º–∞—é', '—Ü–µ–ª—É—é', '—Å–∫—É—á–∞—é'],
                'humor_words': ['—Ö–∞-—Ö–∞', '—Å–º–µ—à–Ω–æ', '–ø—Ä–∏–∫–æ–ª'],
                'typical_length': 'short',
                'common_endings': ['–¶–µ–ª—É—é', '–û–±–Ω–∏–º–∞—é', '–õ—é–±–ª—é']
            },
            'romantic': {
                'formality_words': [],
                'emotional_words': ['–ª—é–±–ª—é', '–æ–±–æ–∂–∞—é', '–Ω–µ–∂–Ω—ã–π', '—Ä–æ–º–∞–Ω—Ç–∏–∫', '–º–µ—á—Ç–∞'],
                'humor_words': [],
                'typical_length': 'medium',
                'common_endings': ['–¶–µ–ª—É—é', '–û–±–Ω–∏–º–∞—é', '–¢–≤–æ–π/–¢–≤–æ—è']
            },
            'friendly': {
                'formality_words': [],
                'emotional_words': ['–∫–ª–∞—Å—Å', '–æ—Ç–ª–∏—á–Ω–æ', '—Å—É–ø–µ—Ä', '–∫—Ä—É—Ç–æ'],
                'humor_words': ['–ª–æ–ª', '–∫–µ–∫', '—Ä–∂–∞–∫–∞', '–ø—Ä–∏–∫–æ–ª'],
                'typical_length': 'short',
                'common_endings': ['–ü–æ–∫–∞', '–î–æ —Å–≤—è–∑–∏', '–£–¥–∞—á–∏']
            },
            'creative': {
                'formality_words': [],
                'emotional_words': ['–≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ', '–∫—Ä–µ–∞—Ç–∏–≤', '—Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ'],
                'humor_words': ['–∏—Ä–æ–Ω–∏—è', '—Å–∞—Ä–∫–∞–∑–º', '—à—É—Ç–∫–∞'],
                'typical_length': 'long',
                'common_endings': ['–¢–≤–æ—Ä—á–µ—Å–∫–∏—Ö —É—Å–ø–µ—Ö–æ–≤', '–í–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è']
            }
        }

    def analyze_context(self, text: str, dialog_context: str = None) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—â–µ–Ω–∏—è"""
        if not text:
            return {
                'detected_context': 'unknown',
                'confidence': 0.0,
                'suggested_contexts': []
            }

        text_lower = text.lower()

        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        if dialog_context and dialog_context in self.context_patterns:
            primary_context = dialog_context
        else:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            context_scores = {}

            for context, patterns in self.context_patterns.items():
                score = 0.0

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
                for word in patterns['formality_words']:
                    if word in text_lower:
                        score += 0.3

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
                for word in patterns['emotional_words']:
                    if word in text_lower:
                        score += 0.2

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —é–º–æ—Ä
                for word in patterns['humor_words']:
                    if word in text_lower:
                        score += 0.2

                context_scores[context] = score

            # –í—ã–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º score
            if context_scores:
                primary_context = max(context_scores.items(), key=lambda x: x[1])[0]
            else:
                primary_context = 'friendly'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥—Ä—É–∂–µ—Å–∫–∏–π

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        if self._is_work_related(text):
            primary_context = 'professional'
        elif self._is_family_related(text):
            primary_context = 'family'
        elif self._is_romantic_related(text):
            primary_context = 'romantic'

        # –°–æ–±–∏—Ä–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        characteristics = {
            'formality': self._calculate_formality(text),
            'emotionality': self._calculate_emotionality(text),
            'humor_level': self._calculate_humor_level(text),
            'emoji_frequency': self._calculate_emoji_frequency(text),
            'message_length': self._classify_length(text),
            'contains_questions': '?' in text,
            'contains_exclamations': '!' in text,
            'word_count': len(text.split())
        }

        return {
            'detected_context': primary_context,
            'confidence': 0.8,  # –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—É—é –æ—Ü–µ–Ω–∫—É
            'characteristics': characteristics,
            'suggested_responses': self._suggest_response_style(primary_context, characteristics)
        }

    def _is_work_related(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∫ —Ä–∞–±–æ—Ç–µ"""
        work_keywords = ['—Ä–∞–±–æ—Ç–∞', '–ø—Ä–æ–µ–∫—Ç', '–∑–∞–¥–∞—á–∞', '–≤—Å—Ç—Ä–µ—á–∞', '–∫–æ–ª–ª–µ–≥–∞',
                         '–Ω–∞—á–∞–ª—å–Ω–∏–∫', '–¥–µ–¥–ª–∞–π–Ω', '–æ—Ç—á–µ—Ç', '–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è']
        return any(keyword in text.lower() for keyword in work_keywords)

    def _is_family_related(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∫ —Å–µ–º—å–µ"""
        family_keywords = ['–º–∞–º–∞', '–ø–∞–ø–∞', '—Ä–æ–¥–∏—Ç–µ–ª–∏', '–±—Ä–∞—Ç', '—Å–µ—Å—Ç—Ä–∞',
                           '—Å–µ–º—å—è', '—Ä–æ–¥–Ω—ã–µ', '–¥–µ—Ç–∏', '–≤–Ω—É–∫–∏']
        return any(keyword in text.lower() for keyword in family_keywords)

    def _is_romantic_related(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∫ —Ä–æ–º–∞–Ω—Ç–∏–∫–µ"""
        romantic_keywords = ['–ª—é–±–ª—é', '–æ–±–æ–∂–∞—é', '–¥–æ—Ä–æ–≥–æ–π', '–º–∏–ª—ã–π', '–ª—é–±–∏–º—ã–π',
                             '—Ä–æ–º–∞–Ω—Ç–∏–∫–∞', '–æ—Ç–Ω–æ—à–µ–Ω–∏—è', '—á—É–≤—Å—Ç–≤–∞', '—Å–µ—Ä–¥—Ü–µ']
        romantic_emojis = ['‚ù§Ô∏è', 'üíï', 'üòò', 'üíã', 'üòç']

        has_keywords = any(keyword in text.lower() for keyword in romantic_keywords)
        has_emojis = any(emoji in text for emoji in romantic_emojis)

        return has_keywords or has_emojis

    def _calculate_formality(self, text: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏"""
        formal_words = ['—É–≤–∞–∂–∞–µ–º—ã–π', '–ø—Ä–æ—à—É', '–ø—Ä–µ–¥–ª–∞–≥–∞—é', '—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ', '–¥–æ–∫—É–º–µ–Ω—Ç',
                        '–¥–æ–≥–æ–≤–æ—Ä', '—Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ', '–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ']

        words = text.lower().split()
        if not words:
            return 0.0

        formal_count = sum(1 for word in words if word in formal_words)
        return min(formal_count / len(words) * 3, 1.0)

    def _calculate_emotionality(self, text: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        emotional_words = ['–ª—é–±–ª—é', '–æ–±–æ–∂–∞—é', '–Ω–µ–Ω–∞–≤–∏–∂—É', '–∑–ª—é—Å—å', '—Ä–∞–¥—É—é—Å—å',
                           '–≥—Ä—É—â—É', '–≤–æ–ª–Ω—É—é—Å—å', '–±–µ—Å–ø–æ–∫–æ—é—Å—å', '–≤–æ—Å—Ö–∏—â–∞—é—Å—å']
        emotional_emojis = ['‚ù§Ô∏è', 'üòç', 'üò¢', 'üòÇ', 'üò°', 'ü•∞', 'üò≠']

        score = 0.0

        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        words = text.lower().split()
        if words:
            emotional_word_count = sum(1 for word in words if word in emotional_words)
            score += emotional_word_count / len(words) * 2

        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —ç–º–æ–¥–∑–∏
        emoji_count = sum(1 for emoji in emotional_emojis if emoji in text)
        score += emoji_count * 0.1

        # –í–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏
        exclamation_count = text.count('!')
        score += min(exclamation_count * 0.05, 0.3)

        return min(score, 1.0)

    def _calculate_humor_level(self, text: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —é–º–æ—Ä–∞"""
        humor_indicators = ['—Ö–∞-—Ö–∞', '—Ö–µ-—Ö–µ', '–ª–æ–ª', '–∫–µ–∫', '—Å–º–µ—à–Ω–æ', '–ø—Ä–∏–∫–æ–ª',
                            '—à—É—Ç–∫–∞', '—é–º–æ—Ä', '–∞–Ω–µ–∫–¥–æ—Ç', 'üòÇ', 'ü§£', 'üòÑ']

        score = 0.0

        for indicator in humor_indicators:
            if indicator in text.lower():
                score += 0.2

        return min(score, 1.0)

    def _calculate_emoji_frequency(self, text: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —á–∞—Å—Ç–æ—Ç—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç–º–æ–¥–∑–∏"""
        # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —ç–º–æ–¥–∑–∏
        emoji_pattern = re.compile(
            r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]'
        )

        emojis = emoji_pattern.findall(text)

        if not text:
            return 0.0

        return min(len(emojis) / len(text) * 100, 1.0)

    def _classify_length(self, text: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è"""
        word_count = len(text.split())

        if word_count < 5:
            return 'short'
        elif word_count < 20:
            return 'medium'
        else:
            return 'long'

    def _suggest_response_style(self, context: str, characteristics: Dict) -> Dict:
        """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å—Ç–∏–ª—å –¥–ª—è –æ—Ç–≤–µ—Ç–∞"""
        suggestions = {
            'professional': {
                'tone': 'formal',
                'emoji_limit': 0,
                'length': 'medium',
                'key_phrases': ['–ë–ª–∞–≥–æ–¥–∞—Ä—é', '–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ', '–ü—Ä–µ–¥–ª–∞–≥–∞—é', '–ü—Ä–æ—à—É —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å']
            },
            'family': {
                'tone': 'warm',
                'emoji_limit': 3,
                'length': 'short',
                'key_phrases': ['–¶–µ–ª—É—é', '–û–±–Ω–∏–º–∞—é', '–õ—é–±–ª—é', '–°–∫—É—á–∞—é']
            },
            'romantic': {
                'tone': 'tender',
                'emoji_limit': 2,
                'length': 'medium',
                'key_phrases': ['–ú–∏–ª—ã–π', '–î–æ—Ä–æ–≥–æ–π', '–õ—é–±–ª—é', '–°–∫—É—á–∞—é –ø–æ —Ç–µ–±–µ']
            },
            'friendly': {
                'tone': 'casual',
                'emoji_limit': 3,
                'length': 'short',
                'key_phrases': ['–ü—Ä–∏–≤–µ—Ç', '–ö–∞–∫ –¥–µ–ª–∞', '–ß—Ç–æ –Ω–æ–≤–æ–≥–æ', '–î–∞–≤–∞–π —Å–æ–∑–≤–æ–Ω–∏–º—Å—è']
            },
            'creative': {
                'tone': 'expressive',
                'emoji_limit': 2,
                'length': 'long',
                'key_phrases': ['–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ', '–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ', '–í–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–µ', '–¢–≤–æ—Ä—á–µ—Å–∫–∏']
            }
        }

        base_suggestion = suggestions.get(context, suggestions['friendly'])

        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–¥ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        adapted = base_suggestion.copy()

        if characteristics['emotionality'] > 0.7:
            adapted['tone'] = 'emotional'
        elif characteristics['formality'] > 0.7:
            adapted['tone'] = 'very_formal'

        if characteristics['emoji_frequency'] > 0.5:
            adapted['emoji_limit'] = min(adapted['emoji_limit'] + 2, 5)

        return adapted

    def extract_style_signature(self, messages: List[str], context: str) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∏–≥–Ω–∞—Ç—É—Ä—É —Å—Ç–∏–ª—è –∏–∑ –Ω–∞–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        if not messages:
            return {}

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        all_characteristics = []

        for msg in messages:
            analysis = self.analyze_context(msg, context)
            all_characteristics.append(analysis['characteristics'])

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        avg_characteristics = {}
        if all_characteristics:
            for key in all_characteristics[0].keys():
                if isinstance(all_characteristics[0][key], (int, float)):
                    values = [ch[key] for ch in all_characteristics if isinstance(ch[key], (int, float))]
                    if values:
                        avg_characteristics[key] = np.mean(values)

        # –°–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞
        common_words = self._extract_common_words(messages)

        # –ß–∞—Å—Ç—ã–µ —Ñ—Ä–∞–∑—ã
        common_phrases = self._extract_common_phrases(messages)

        return {
            'context': context,
            'avg_characteristics': avg_characteristics,
            'common_words': common_words[:10],
            'common_phrases': common_phrases[:5],
            'message_count': len(messages),
            'style_description': self._describe_style(avg_characteristics)
        }

    def _extract_common_words(self, messages: List[str]) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—â–∏–µ —Å–ª–æ–≤–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        all_words = []

        for msg in messages:
            words = re.findall(r'\b[–∞-—è—ë]{3,}\b', msg.lower())
            filtered_words = [word for word in words if word not in self.stop_words]
            all_words.extend(filtered_words)

        # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
        from collections import Counter
        word_counts = Counter(all_words)

        return [word for word, count in word_counts.most_common(20)]

    def _extract_common_phrases(self, messages: List[str]) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –∏—â–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ 2-3 —Å–ª–æ–≤
        phrases = []

        for msg in messages:
            words = msg.lower().split()
            for i in range(len(words) - 1):
                phrase = ' '.join(words[i:i + 2])
                if len(phrase) > 5 and phrase not in self.stop_words:
                    phrases.append(phrase)

        # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
        from collections import Counter
        phrase_counts = Counter(phrases)

        return [phrase for phrase, count in phrase_counts.most_common(10) if count > 1]

    def _describe_style(self, characteristics: Dict) -> str:
        """–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∏–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
        if not characteristics:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∏–ª—å"

        descriptions = []

        # –§–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å
        formality = characteristics.get('formality', 0)
        if formality > 0.7:
            descriptions.append("—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π")
        elif formality > 0.3:
            descriptions.append("—É–º–µ—Ä–µ–Ω–Ω–æ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π")
        else:
            descriptions.append("–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π")

        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        emotionality = characteristics.get('emotionality', 0)
        if emotionality > 0.7:
            descriptions.append("—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π")
        elif emotionality > 0.3:
            descriptions.append("—É–º–µ—Ä–µ–Ω–Ω–æ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π")
        else:
            descriptions.append("—Å–¥–µ—Ä–∂–∞–Ω–Ω—ã–π")

        # –î–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
        avg_length = characteristics.get('word_count', 0)
        if avg_length > 15:
            descriptions.append("—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π")
        elif avg_length > 5:
            descriptions.append("—É–º–µ—Ä–µ–Ω–Ω—ã–π –ø–æ –¥–ª–∏–Ω–µ")
        else:
            descriptions.append("–ª–∞–∫–æ–Ω–∏—á–Ω—ã–π")

        return ', '.join(descriptions)